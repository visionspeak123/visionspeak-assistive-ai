
 {% load static %}
 <!DOCTYPE html>
 <html lang="en">
 <head>
     <meta charset="UTF-8">
     <meta name="viewport" content="width=device-width, initial-scale=1.0">
     <title>Object Detection - AI Laika</title>
     <link rel="stylesheet" href="{% static 'style.css' %}">
     <style>
         body {
        font-family: Arial, sans-serif;
        margin: 35%;
        margin-top: 0rem;
        padding: 0;
        background: white;
        color: blue;
        text-align: center;
        border: 2px solid blue;
        width: 400px;
        height: 697px;
        align-items: center;
        justify-items: center;
        
    }
         .container {
             position: relative;
         }
         video {
             display: block;
             max-width: 100%;
             border: 2px solid #333;
             border-radius: 10px;
         }
         canvas {
             position: absolute;
             top: 0;
             left: 0;
             border-radius: 10px;
             pointer-events: none; /* Allows clicks to pass through the canvas */
         }
         top-design,
        .bottom-design {
            position: absolute;
            width: 90px; /* Adjust the size */
            height: auto;
        }

        .top-design {
            top:0.0%;
            left: 11.55%;
            margin-right: 20x;
            transform: translateX(-50%);
        }
        .bottom-design {
            bottom:3.4%;
            left: 38%;
            transform: translateX(-50%);
        }
     </style>
 </head>
 <body>
     <div class="container">
        <div class="top-design"></div>
        <img src="{% static 'images/lo.png' %}" height="75px" width="400px" alt="Top Design">
        </div>
         <h1>Object Detection</h1>
         <video id="video" autoplay></video>
         <canvas id="canvas"></canvas>
     </div><br><br><br><br><br><br>
     <br><br><br>
     <div class="bottom-design"></div>
            <img src="{% static 'images/dw.png' %}" height="75px" width="405px" alt="Bottom Design">
        </div>
 
     <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
     <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
     <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: true
            });
            video.srcObject = stream;
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve();
                };
            });
        }

        async function detectObjects() {
            const model = await cocoSsd.load();
            console.log("Model loaded");

            function detectFrame() {
                model.detect(video).then(predictions => {
                    drawPredictions(predictions);
                    speakPredictions(predictions); // Announce the predictions
                    requestAnimationFrame(detectFrame);
                });
            }

            detectFrame();
        }

        function drawPredictions(predictions) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            predictions.forEach(prediction => {
                const [x, y, width, height] = prediction.bbox;
                ctx.beginPath();
                ctx.rect(x, y, width, height);
                ctx.lineWidth = 2;
                ctx.strokeStyle = 'red';
                ctx.fillStyle = 'red';
                ctx.stroke();
                ctx.fillText(prediction.class, x, y > 10 ? y - 5 : 10);
            });
        }

        function speakPredictions(predictions) {
            const speech = window.speechSynthesis;
            const utterance = new SpeechSynthesisUtterance();
            const objectsToAnnounce = predictions.map(prediction => {
                const [x, y, width, height] = prediction.bbox;
                const distance = calculateDistance(width); // Customize this function based on your distance estimation
                const position = determinePosition(x, width);
                return `Detected ${prediction.class} at ${position} with a distance of ${distance} meters.`;
            }).join(' ');

            utterance.text = objectsToAnnounce;
            utterance.voice = speech.getVoices().find(voice => voice.name.toLowerCase().includes('female')); // Set a female voice
            speech.speak(utterance);
        }

        function calculateDistance(width) {
            const knownWidth = 0.5; // known width of the object in meters
            const focalLength = 700; // Adjust this value based on your camera calibration
            const distance = (knownWidth * focalLength) / width;
            return distance.toFixed(2); // Format to 2 decimal places
        }

        function determinePosition(x, width) {
            const centerX = canvas.width / 2;
            const objectCenterX = x + width / 2;
            const threshold = canvas.width * 0.1; // 10% of canvas width

            if (objectCenterX < centerX - threshold) {
                return 'left';
            } else if (objectCenterX > centerX + threshold) {
                return 'right';
            } else {
                return 'center';
            }
        }

        function handleCommand(command) {
            command = command.toLowerCase();
            if (command.includes('go back')) {
                window.location.href = '/explore/';
            }
        }

        function startListening() {
            const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = 'en-US';
            recognition.interimResults = false;
            recognition.continuous = true;

            recognition.onresult = (event) => {
                const command = event.results[0][0].transcript;
                handleCommand(command);
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
            };

            recognition.start();
        }

        async function main() {
            await setupCamera();
            video.play();
            detectObjects();
            startListening();
        }

        main();
    </script>
 </body>
 </html>
 